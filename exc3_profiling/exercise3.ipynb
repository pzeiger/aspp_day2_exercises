{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required libraries, function and built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "import matmult_functionalized as mf\n",
    "import matmult_functionalized_opt as mfo\n",
    "import euler72\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we profile the code using the Python inbuilt ```cProfile```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 30 08:55:18 2020    matmult_cProfile.txt\n",
      "\n",
      "         726254 function calls (726211 primitive calls) in 5.854 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 120 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      4/1    0.000    0.000    5.854    5.854 {built-in method builtins.exec}\n",
      "        1    5.603    5.603    5.854    5.854 matmult.py:2(<module>)\n",
      "   125250    0.034    0.000    0.205    0.000 /home/paul/miniconda3/lib/python3.7/random.py:218(randint)\n",
      "   125250    0.075    0.000    0.171    0.000 /home/paul/miniconda3/lib/python3.7/random.py:174(randrange)\n",
      "      250    0.016    0.000    0.123    0.000 matmult.py:11(<listcomp>)\n",
      "      250    0.014    0.000    0.112    0.000 matmult.py:16(<listcomp>)\n",
      "   125250    0.067    0.000    0.096    0.000 /home/paul/miniconda3/lib/python3.7/random.py:224(_randbelow)\n",
      "   158635    0.020    0.000    0.020    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "   125250    0.008    0.000    0.008    0.000 {method 'bit_length' of 'int' objects}\n",
      "    63010    0.006    0.000    0.006    0.000 {built-in method builtins.len}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6e43e2b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python -m cProfile -o matmult_cProfile.txt matmult.py >>/dev/null\n",
    "p = pstats.Stats('matmult_cProfile.txt')\n",
    "p.sort_stats('cumulative').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the code is not functionalized, interpreting the profiling output is not that straightforward. We can see from above's output that it seems that the most expensive part of the program starts on line 2, which imports the package ```random```. Reading further, we see, however, that the functions ```randint()``` and ```randrange()``` are only responsible for a minor part of the execuation time. In order to find the real bottleneck, we functionalize the code. The result can be found in the file ```matmult_functionalized.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          724305 function calls in 3.757 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 16 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.757    3.757 {built-in method builtins.exec}\n",
      "        1    0.001    0.001    3.757    3.757 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.756    3.756 matmult_functionalized.py:42(main)\n",
      "        1    3.501    3.501    3.505    3.505 matmult_functionalized.py:7(matmult)\n",
      "   125250    0.035    0.000    0.213    0.000 random.py:218(randint)\n",
      "   125250    0.077    0.000    0.178    0.000 random.py:174(randrange)\n",
      "        1    0.001    0.001    0.128    0.128 matmult_functionalized.py:33(get_Y)\n",
      "      250    0.018    0.000    0.127    0.001 matmult_functionalized.py:38(<listcomp>)\n",
      "        1    0.001    0.001    0.124    0.124 matmult_functionalized.py:24(get_X)\n",
      "      250    0.019    0.000    0.123    0.000 matmult_functionalized.py:29(<listcomp>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6e4ee4110>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r mf.main(print_result=False)\n",
    "pff.sort_stats('cumulative').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the majority of the time is spent inside ```matmult()```. Thus it seems fruitful to optimize this function for speed. In order to verify this, we move on to the ```line_profiler``` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 16.3774 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: matmult at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def matmult(X,Y):\n",
      "     8                                               \n",
      "     9                                               # result is Nx(N+1)\n",
      "    10         1          0.0      0.0      0.0      result = []\n",
      "    11       251         95.0      0.4      0.0      for i in range(len(X)):\n",
      "    12       250       1375.0      5.5      0.0          result.append([0] * (len(Y[0])))\n",
      "    13                                               \n",
      "    14                                               # iterate through rows of X\n",
      "    15       251        108.0      0.4      0.0      for i in range(len(X)):\n",
      "    16                                                   # iterate through columns of Y\n",
      "    17     63000      21561.0      0.3      0.1          for j in range(len(Y[0])):\n",
      "    18                                                       # iterate through rows of Y\n",
      "    19  15750250    5584307.0      0.4     34.1              for k in range(len(Y)):\n",
      "    20  15687500   10770002.0      0.7     65.8                  result[i][j] += X[i][k] * Y[k][j]\n",
      "    21         1          0.0      0.0      0.0      return result\n",
      "\n",
      "Total time: 0.305101 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: get_X at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                           def get_X(N):\n",
      "    25                                               \"\"\"Return random NxN matrix\n",
      "    26                                               \"\"\"\n",
      "    27         1          1.0      1.0      0.0      X = []\n",
      "    28       251        197.0      0.8      0.1      for i in range(N):\n",
      "    29       250     304903.0   1219.6     99.9          X.append([random.randint(0,100) for r in range(N)])\n",
      "    30         1          0.0      0.0      0.0      return X\n",
      "\n",
      "Total time: 0.313685 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: get_Y at line 33\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    33                                           def get_Y(N):\n",
      "    34                                               \"\"\"Return random Nx(N+1) matrix\n",
      "    35                                               \"\"\"\n",
      "    36         1          0.0      0.0      0.0      Y = []\n",
      "    37       251        174.0      0.7      0.1      for i in range(N):\n",
      "    38       250     313510.0   1254.0     99.9          Y.append([random.randint(0,100) for r in range(N+1)])\n",
      "    39         1          1.0      1.0      0.0      return Y\n",
      "\n",
      "Total time: 27.2462 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: main at line 42\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    42                                           def main(print_result=True):\n",
      "    43                                               \"\"\"Main function binding together the other functions.\n",
      "    44                                               \"\"\"\n",
      "    45                                           #    random.seed(314156345)\n",
      "    46         1          1.0      1.0      0.0      N = 250\n",
      "    47         1     305405.0 305405.0      1.1      X = get_X(N)\n",
      "    48         1     313987.0 313987.0      1.2      Y = get_Y(N)\n",
      "    49         1   26626768.0 26626768.0     97.7      result = matmult(X,Y)\n",
      "    50         1          1.0      1.0      0.0      if print_result:\n",
      "    51                                                   for r in result:\n",
      "    52                                                       print(r)\n",
      "    53                                               \n",
      "    54         1          0.0      0.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f mf.matmult -f mf.get_X -f mf.get_Y -f mf.main mf.main(print_result=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above's ```line_profiler``` output, we see that the majority of the time (~98%) is spent inside the function ```matmul()```. Inside the function ```matmul()```, most of the time is spent by performing the innermost loop over the result array and computing its values. Therefore lines 19 and 20 would be the point where one would start optimizing the code for speed.\n",
    "\n",
    "Next we investigate the memory characteristics of our code using the ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Profile printout saved to text file matmult_functionalized.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    42     50.7 MiB     50.7 MiB   def main(print_result=True):\n",
      "    43                                 \"\"\"Main function binding together the other functions.\n",
      "    44                                 \"\"\"\n",
      "    45                             #    random.seed(314156345)\n",
      "    46     50.7 MiB      0.0 MiB       N = 250\n",
      "    47     50.9 MiB      0.2 MiB       X = get_X(N)\n",
      "    48     51.4 MiB      0.5 MiB       Y = get_Y(N)\n",
      "    49     53.8 MiB      2.4 MiB       result = matmult(X,Y)\n",
      "    50     53.8 MiB      0.0 MiB       if print_result:\n",
      "    51                                     for r in result:\n",
      "    52                                         print(r)\n",
      "    53                                 \n",
      "    54     53.8 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%mprun -T matmult_functionalized.py.mprof -f mf.main mf.main(print_result=False)\n",
    "print(open('matmult_functionalized.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above's output is somewhat confusing. We can see that most memory is created when the main function is entered, i.e., when the program starts. The overall memory consumption is, howerver, low and the increment in the program is just a few MB where arrays are populated. Optimizing for memory use seems thus not very necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ```phi()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "          151506 function calls in 10.398 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 24 to 8 due to restriction <8>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   10.398   10.398 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   10.398   10.398 <string>:1(<module>)\n",
      "        1    0.004    0.004   10.398   10.398 euler72.py:62(main)\n",
      "     9999   10.347    0.001   10.393    0.001 euler72.py:36(phi)\n",
      "     9999    0.036    0.000    0.046    0.000 euler72.py:22(factorize)\n",
      "    99314    0.008    0.000    0.008    0.000 {built-in method math.sqrt}\n",
      "    32153    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.001    0.001    0.001    0.001 euler72.py:5(gen_primes)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6e4115d10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = %prun -r -q euler72.main(fast=False)\n",
    "ps.sort_stats('cumulative').print_stats(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the time is spent inside the function ```phi()```. Thus speed optimization is most effective there. The program comes with an alternative function ```fast_phi()```, which is profiled further below. In order to see, which line takes longest to execute, we look at the output of ```line_profiler```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.220518 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: factorize at line 22\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    22                                           def factorize(n, primes):\n",
      "    23      9999       6397.0      0.6      2.9      factors = []\n",
      "    24      9999       4377.0      0.4      2.0      init_n = n\n",
      "    25     96347      35473.0      0.4     16.1      for p in primes:\n",
      "    26    118736      63728.0      0.5     28.9          while(n%p == 0):\n",
      "    27     22389      13012.0      0.6      5.9              n = n/p\n",
      "    28     22389      21281.0      1.0      9.7              factors.append(p)\n",
      "    29     96347      57053.0      0.6     25.9          if(p > sqrt(n)):\n",
      "    30      9999       3992.0      0.4      1.8              break\n",
      "    31      9999       5017.0      0.5      2.3      if(n > 1):\n",
      "    32      9596       6531.0      0.7      3.0          factors.append(n)\n",
      "    33      9999       3657.0      0.4      1.7      return factors\n",
      "\n",
      "Total time: 193.06 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: phi at line 36\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    36                                           def phi(n, primes):\n",
      "    37      9999     373116.0     37.3      0.2      factors = factorize(n,primes)\n",
      "    38      9999       4811.0      0.5      0.0      p = 1\n",
      "    39                                           \n",
      "    40  49995000   20046305.0      0.4     10.4      for i in range(2,n):\n",
      "    41  49985001   18594365.0      0.4      9.6          flag = True\n",
      "    42 140823164   56489821.0      0.4     29.3          for f in factors:\n",
      "    43 110435678   50149606.0      0.5     26.0              if i%f == 0:\n",
      "    44  19597515    7572361.0      0.4      3.9                  flag = False\n",
      "    45  19597515    7686637.0      0.4      4.0                  break\n",
      "    46  49985001   19478589.0      0.4     10.1          if flag:\n",
      "    47  30387486   12658793.0      0.4      6.6              p+=1\n",
      "    48      9999       5127.0      0.5      0.0      return p\n",
      "\n",
      "Total time: 366.155 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: main at line 62\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    62                                           def main(fast=True):\n",
      "    63         1       2885.0   2885.0      0.0      primes = gen_primes(1000)\n",
      "    64         1          1.0      1.0      0.0      m = 10000\n",
      "    65                                               #m = 8\n",
      "    66         1          1.0      1.0      0.0      fraq = 0\n",
      "    67         1          1.0      1.0      0.0      if fast:\n",
      "    68                                                   for i in range(2,m+1):\n",
      "    69                                                       fraq += fast_phi(i,primes)\n",
      "    70                                               else:\n",
      "    71     10000       6718.0      0.7      0.0          for i in range(2,m+1):\n",
      "    72      9999  366145559.0  36618.2    100.0              fraq += phi(i,primes)\n",
      "    73                                           \n",
      "    74         1        158.0    158.0      0.0      print(fraq)\n",
      "    75         1          1.0      1.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f euler72.main -f euler72.phi -f euler72.factorize euler72.main(fast=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that most of the time is spent executing lines 41-48 in function ```phi()```. These lines include two loops and logic operations, which should be the point to look out for speed optimizations. Finally we look at the memory consumption of the program using ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "\n",
      "\n",
      "*** Profile printout saved to text file euler72_slow.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    62     52.2 MiB     52.2 MiB   def main(fast=True):\n",
      "    63     52.2 MiB      0.0 MiB       primes = gen_primes(1000)\n",
      "    64     52.2 MiB      0.0 MiB       m = 10000\n",
      "    65                                 #m = 8\n",
      "    66     52.2 MiB      0.0 MiB       fraq = 0\n",
      "    67     52.2 MiB      0.0 MiB       if fast:\n",
      "    68                                     for i in range(2,m+1):\n",
      "    69                                         fraq += fast_phi(i,primes)\n",
      "    70                                 else:\n",
      "    71     52.2 MiB      0.0 MiB           for i in range(2,m+1):\n",
      "    72     52.2 MiB      0.0 MiB               fraq += phi(i,primes)\n",
      "    73                             \n",
      "    74     52.2 MiB      0.0 MiB       print(fraq)\n",
      "    75     52.2 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%mprun -T euler72_slow.py.mprof -f euler72.main euler72.main(fast=False)\n",
    "print(open('euler72_slow.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ```fast_phi()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "          161505 function calls in 0.055 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.055    0.055 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.055    0.055 <string>:1(<module>)\n",
      "        1    0.002    0.002    0.055    0.055 euler72.py:62(main)\n",
      "     9999    0.011    0.000    0.051    0.000 euler72.py:51(fast_phi)\n",
      "     9999    0.031    0.000    0.040    0.000 euler72.py:22(factorize)\n",
      "    99314    0.007    0.000    0.007    0.000 {built-in method math.sqrt}\n",
      "    32153    0.002    0.000    0.002    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.001    0.001    0.001    0.001 euler72.py:5(gen_primes)\n",
      "    10000    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6e4115550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r -q euler72.main()\n",
    "pff.sort_stats('cumulative').print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of the time is spent in function ```factorize()``` starting in line 23, which is called by the function ```fast_pi()```, which in turn is called by ```main()```. Thus speed optimization seems to be most fruitful inside the factorize function. In comparison with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.167634 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: factorize at line 22\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    22                                           def factorize(n, primes):\n",
      "    23      9999       3381.0      0.3      2.0      factors = []\n",
      "    24      9999       3313.0      0.3      2.0      init_n = n\n",
      "    25     96347      31738.0      0.3     18.9      for p in primes:\n",
      "    26    118736      54985.0      0.5     32.8          while(n%p == 0):\n",
      "    27     22389       8424.0      0.4      5.0              n = n/p\n",
      "    28     22389       9536.0      0.4      5.7              factors.append(p)\n",
      "    29     96347      41995.0      0.4     25.1          if(p > sqrt(n)):\n",
      "    30      9999       3316.0      0.3      2.0              break\n",
      "    31      9999       3809.0      0.4      2.3      if(n > 1):\n",
      "    32      9596       4140.0      0.4      2.5          factors.append(n)\n",
      "    33      9999       2997.0      0.3      1.8      return factors\n",
      "\n",
      "Total time: 0.345718 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: fast_phi at line 51\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    51                                           def fast_phi(n, primes):\n",
      "    52      9999     301280.0     30.1     87.1      factors = factorize(n,primes)\n",
      "    53      9999       4284.0      0.4      1.2      phi = factors[0]-1\n",
      "    54     31985      15258.0      0.5      4.4      for i in range(1,len(factors)):\n",
      "    55     21986      10514.0      0.5      3.0          if(factors[i] == factors[i-1]):\n",
      "    56      7685       4740.0      0.6      1.4              phi *= (factors[i]-1)*(factors[i])/(factors[i]-1)\n",
      "    57                                                   else:\n",
      "    58     14301       6478.0      0.5      1.9              phi *= (factors[i]-1)\n",
      "    59      9999       3164.0      0.3      0.9      return phi\n",
      "\n",
      "Total time: 0.394817 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: main at line 62\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    62                                           def main(fast=True):\n",
      "    63         1       2683.0   2683.0      0.7      primes = gen_primes(1000)\n",
      "    64         1          1.0      1.0      0.0      m = 10000\n",
      "    65                                               #m = 8\n",
      "    66         1          1.0      1.0      0.0      fraq = 0\n",
      "    67         1          0.0      0.0      0.0      if fast:\n",
      "    68     10000       4213.0      0.4      1.1          for i in range(2,m+1):\n",
      "    69      9999     387809.0     38.8     98.2              fraq += fast_phi(i,primes)\n",
      "    70                                               else:\n",
      "    71                                                   for i in range(2,m+1):\n",
      "    72                                                       fraq += phi(i,primes)\n",
      "    73                                           \n",
      "    74         1        109.0    109.0      0.0      print(fraq)\n",
      "    75         1          1.0      1.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f euler72.main -f euler72.fast_phi -f euler72.factorize euler72.main()\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the line-by-line results, we observe that the line calling function ```fast_phi()``` requires most execution time inside ```main()```. However, in comparison with the implementation of ```phi()```, most time inside ```fast_phi()``` is now spent on factorizing the prime number inside ```factorize()```. We therefore see that the optimizations have had a significant impact. The new version avoids a double loop and significantly simplifies the logic.\n",
    "\n",
    "Finally, we have a look at the memory consumption using ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "\n",
      "\n",
      "*** Profile printout saved to text file euler72.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    62     52.2 MiB     52.2 MiB   def main(fast=True):\n",
      "    63     52.2 MiB      0.0 MiB       primes = gen_primes(1000)\n",
      "    64     52.2 MiB      0.0 MiB       m = 10000\n",
      "    65                                 #m = 8\n",
      "    66     52.2 MiB      0.0 MiB       fraq = 0\n",
      "    67     52.2 MiB      0.0 MiB       if fast:\n",
      "    68     52.2 MiB      0.0 MiB           for i in range(2,m+1):\n",
      "    69     52.2 MiB      0.0 MiB               fraq += fast_phi(i,primes)\n",
      "    70                                 else:\n",
      "    71                                     for i in range(2,m+1):\n",
      "    72                                         fraq += phi(i,primes)\n",
      "    73                             \n",
      "    74     52.2 MiB      0.0 MiB       print(fraq)\n",
      "    75     52.2 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%mprun -T euler72.py.mprof -f euler72.main euler72.main()\n",
    "print(open('euler72.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```euler72``` program does not seem to consume measurable quantities of memory except for the intialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the code for speed, we replace many of the loops with generator expressions and make use of Python's built-in function ```sum()``` for Python arrays, which is expected to speed up the evaluation of the matrix multiplication, which was identified to be the bottleneck of this code in step 3a). This optimization is taken from:\n",
    "\n",
    "https://www.programiz.com/python-programming/examples/multiply-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture time_mfo_main\n",
    "%timeit mfo.main(print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture time_mf_main\n",
    "%timeit mf.main(print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6 s +- 60.9 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "1.74 s ± 82.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(str(time_mfo_main).split('\\n')[-2])\n",
    "%timeit mfo.main(print_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.83 s +- 209 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "4.01 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(str(time_mf_main).split('\\n')[-2])\n",
    "%timeit mf.main(print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above's output we see that the execution time of our program has measurably improved due to the optimizations we have performed (it nearly halved). Using profilers, we investigate where the performance has been improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          16473227 function calls in 3.572 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.823    3.823 {built-in method builtins.exec}\n",
      "        1    0.001    0.001    3.823    3.823 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.822    3.822 matmult_functionalized_opt.py:23(main)\n",
      "        1    0.000    0.000    3.536    3.536 matmult_functionalized_opt.py:7(matmult)\n",
      "        1    0.003    0.003    3.536    3.536 matmult_functionalized_opt.py:8(<listcomp>)\n",
      "    62750    1.515    0.000    3.320    0.000 {built-in method builtins.sum}\n",
      " 15750250    1.805    0.000    1.805    0.000 matmult_functionalized_opt.py:8(<genexpr>)\n",
      "   125250    0.041    0.000    0.248    0.000 random.py:218(randint)\n",
      "   125250    0.090    0.000    0.206    0.000 random.py:174(randrange)\n",
      "        1    0.000    0.000    0.153    0.153 matmult_functionalized_opt.py:17(get_Y)\n",
      "        1    0.001    0.001    0.153    0.153 matmult_functionalized_opt.py:20(<listcomp>)\n",
      "        1    0.000    0.000    0.134    0.134 matmult_functionalized_opt.py:11(get_X)\n",
      "        1    0.000    0.000    0.134    0.134 matmult_functionalized_opt.py:14(<listcomp>)\n",
      "   125250    0.082    0.000    0.116    0.000 random.py:224(_randbelow)\n",
      "   159217    0.025    0.000    0.025    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "   125250    0.010    0.000    0.010    0.000 {method 'bit_length' of 'int' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6e87607d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r mfo.main(print_result=False)\n",
    "pff.sort_stats('cumulative').print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the profiling results it seems that our improvements have decreased the time spent in functions ```matmult()```, ```get_X()```, and ```get_Y()``` by a little bit, but not by an amount that explains the difference in execution time observed earlier. Since profiling influences the execution speed and it might influence execution speeds of different implementations differntly, we cannot draw meaningful conclusions from here. Thus we move on to the ```line_profiler```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 5.90789 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: matmult at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def matmult(X,Y):\n",
      "     8         1    5907891.0 5907891.0    100.0      return [[sum(a*b for a,b in zip(X_row,Y_col)) for Y_col in zip(*Y)] for X_row in X]\n",
      "\n",
      "Total time: 0.318195 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: get_X at line 11\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    11                                           def get_X(N):\n",
      "    12                                               \"\"\"Return random NxN numpy matrix\n",
      "    13                                               \"\"\"\n",
      "    14         1     318195.0 318195.0    100.0      return [[random.randint(0,100) for j in range(N) ] for i in range(N)]\n",
      "\n",
      "Total time: 0.306631 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: get_Y at line 17\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    17                                           def get_Y(N):\n",
      "    18                                               \"\"\"Return random Nx(N+1) numpy matrix\n",
      "    19                                               \"\"\"\n",
      "    20         1     306631.0 306631.0    100.0      return [[random.randint(0,100) for j in range(N+1)] for i in range(N)]\n",
      "\n",
      "Total time: 6.53277 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: main at line 23\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    23                                           def main(print_result=True):\n",
      "    24                                               \"\"\"Main function binding together the other functions.\n",
      "    25                                               \"\"\"\n",
      "    26                                           #    random.seed(314156345)\n",
      "    27         1          8.0      8.0      0.0      N = 250\n",
      "    28         1     318216.0 318216.0      4.9      X = get_X(N)\n",
      "    29         1     306642.0 306642.0      4.7      Y = get_Y(N)\n",
      "    30         1    5907904.0 5907904.0     90.4      result = matmult(X,Y)\n",
      "    31         1          2.0      2.0      0.0      if print_result:\n",
      "    32                                                   for r in result:\n",
      "    33                                                       print(r)\n",
      "    34                                               \n",
      "    35         1          0.0      0.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f mfo.matmult -f mfo.get_X -f mfo.get_Y -f mfo.main mfo.main(print_result=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the relative time spent in the functions has changed significantly in comparison with the results from 3a). Now the matrix multiplication takes around 89% of the time, whereas it took around 98% of the time before. This means that we have managed to improve the matrix multiplication execution speed by more than we managed to decrease the array creation speed in ```get_X()``` and ```get_Y()```. Lastly we have a look at the memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Profile printout saved to text file matmult_functionalized_opt.py.main.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    27     51.6 MiB     51.6 MiB   def main(print_result=True):\n",
      "    28                                 \"\"\"Optimized main function binding together the other functions.\n",
      "    29                                 \"\"\"\n",
      "    30                             #    random.seed(314156345)\n",
      "    31     51.6 MiB      0.0 MiB       N = 250\n",
      "    32     51.6 MiB      0.0 MiB       X = get_X(N)\n",
      "    33     52.1 MiB      0.5 MiB       Y = get_Y(N)\n",
      "    34     54.2 MiB      2.0 MiB       result = matmult(X,Y)\n",
      "    35     54.2 MiB      0.0 MiB       if print_result:\n",
      "    36                                     for r in result:\n",
      "    37                                         print(r)\n",
      "    38                                 \n",
      "    39     54.2 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%mprun -T matmult_functionalized_opt.py.main.mprof -f mfo.main mfo.main(print_result=False)\n",
    "print(open('matmult_functionalized_opt.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory requirements of the code have not changed dramatically. However, I am under the impression that the ```memory_profiler``` is not the best quality software and that there are still quite a few rough edges in its implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
