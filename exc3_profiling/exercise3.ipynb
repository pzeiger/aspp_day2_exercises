{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required libraries, function and built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "import matmult_functionalized as mf\n",
    "import matmult_functionalized_opt as mfo\n",
    "import euler72\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we profile the code using the Python inbuilt ```cProfile```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 29 17:12:20 2020    matmult_cProfile.txt\n",
      "\n",
      "         726283 function calls (726240 primitive calls) in 5.705 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 120 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      4/1    0.000    0.000    5.705    5.705 {built-in method builtins.exec}\n",
      "        1    5.455    5.455    5.705    5.705 matmult.py:2(<module>)\n",
      "   125250    0.034    0.000    0.203    0.000 /home/paul/miniconda3/lib/python3.7/random.py:218(randint)\n",
      "   125250    0.075    0.000    0.169    0.000 /home/paul/miniconda3/lib/python3.7/random.py:174(randrange)\n",
      "      250    0.018    0.000    0.126    0.001 matmult.py:9(<listcomp>)\n",
      "      250    0.014    0.000    0.110    0.000 matmult.py:14(<listcomp>)\n",
      "   125250    0.065    0.000    0.094    0.000 /home/paul/miniconda3/lib/python3.7/random.py:224(_randbelow)\n",
      "   158664    0.020    0.000    0.020    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "   125250    0.008    0.000    0.008    0.000 {method 'bit_length' of 'int' objects}\n",
      "    63010    0.005    0.000    0.005    0.000 {built-in method builtins.len}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff0ec147c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python -m cProfile -o matmult_cProfile.txt matmult.py >>/dev/null\n",
    "p = pstats.Stats('matmult_cProfile.txt')\n",
    "p.sort_stats('cumulative').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the code is not functionalized, interpreting the profiling output is not that straightforward. We can see from above's output that it seems that the most expensive part of the program starts on line 2, which imports the package ```random```. Reading further, we see, however, that the functions ```randint()``` and ```randrange()``` are only responsible for a minor part of the execuation time. In order to find the real bottleneck, we functionalize the code. The result can be found in the file ```matmult_functionalized.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          724108 function calls in 3.624 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 16 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.624    3.624 {built-in method builtins.exec}\n",
      "        1    0.001    0.001    3.624    3.624 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.623    3.623 matmult_functionalized.py:42(main)\n",
      "        1    3.391    3.391    3.396    3.396 matmult_functionalized.py:7(matmult)\n",
      "   125250    0.033    0.000    0.197    0.000 random.py:218(randint)\n",
      "   125250    0.071    0.000    0.164    0.000 random.py:174(randrange)\n",
      "        1    0.000    0.000    0.116    0.116 matmult_functionalized.py:24(get_X)\n",
      "      250    0.015    0.000    0.115    0.000 matmult_functionalized.py:29(<listcomp>)\n",
      "        1    0.000    0.000    0.112    0.112 matmult_functionalized.py:33(get_Y)\n",
      "      250    0.014    0.000    0.112    0.000 matmult_functionalized.py:38(<listcomp>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff0e847a050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r mf.main(print_result=False)\n",
    "pff.sort_stats('cumulative').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the majority of the time is spent inside ```matmult()```. Thus it seems fruitful to optimize this function for speed. In order to verify this, we move on to the ```line_profiler``` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 17.2076 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: matmult at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def matmult(X,Y):\n",
      "     8                                               \n",
      "     9                                               # result is Nx(N+1)\n",
      "    10         1          0.0      0.0      0.0      result = []\n",
      "    11       251        112.0      0.4      0.0      for i in range(len(X)):\n",
      "    12       250       1646.0      6.6      0.0          result.append([0] * (len(Y[0])))\n",
      "    13                                               \n",
      "    14                                               # iterate through rows of X\n",
      "    15       251        118.0      0.5      0.0      for i in range(len(X)):\n",
      "    16                                                   # iterate through columns of Y\n",
      "    17     63000      23161.0      0.4      0.1          for j in range(len(Y[0])):\n",
      "    18                                                       # iterate through rows of Y\n",
      "    19  15750250    5865795.0      0.4     34.1              for k in range(len(Y)):\n",
      "    20  15687500   11316787.0      0.7     65.8                  result[i][j] += X[i][k] * Y[k][j]\n",
      "    21         1          1.0      1.0      0.0      return result\n",
      "\n",
      "Total time: 0.376245 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: get_X at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                           def get_X(N):\n",
      "    25                                               \"\"\"Return random NxN matrix\n",
      "    26                                               \"\"\"\n",
      "    27         1          1.0      1.0      0.0      X = []\n",
      "    28       251        425.0      1.7      0.1      for i in range(N):\n",
      "    29       250     375819.0   1503.3     99.9          X.append([random.randint(0,100) for r in range(N)])\n",
      "    30         1          0.0      0.0      0.0      return X\n",
      "\n",
      "Total time: 0.320239 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: get_Y at line 33\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    33                                           def get_Y(N):\n",
      "    34                                               \"\"\"Return random Nx(N+1) matrix\n",
      "    35                                               \"\"\"\n",
      "    36         1          1.0      1.0      0.0      Y = []\n",
      "    37       251        249.0      1.0      0.1      for i in range(N):\n",
      "    38       250     319988.0   1280.0     99.9          Y.append([random.randint(0,100) for r in range(N+1)])\n",
      "    39         1          1.0      1.0      0.0      return Y\n",
      "\n",
      "Total time: 28.4428 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "Function: main at line 42\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    42                                           def main(print_result=True):\n",
      "    43                                               \"\"\"Main function binding together the other functions.\n",
      "    44                                               \"\"\"\n",
      "    45                                           #    random.seed(314156345)\n",
      "    46         1          1.0      1.0      0.0      N = 250\n",
      "    47         1     376799.0 376799.0      1.3      X = get_X(N)\n",
      "    48         1     320611.0 320611.0      1.1      Y = get_Y(N)\n",
      "    49         1   27745363.0 27745363.0     97.5      result = matmult(X,Y)\n",
      "    50         1          1.0      1.0      0.0      if print_result:\n",
      "    51                                                   for r in result:\n",
      "    52                                                       print(r)\n",
      "    53                                               \n",
      "    54         1          1.0      1.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f mf.matmult -f mf.get_X -f mf.get_Y -f mf.main mf.main(print_result=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above's ```line_profiler``` output, we see that the majority of the time (~98%) is spent inside the function ```matmul()```. Inside the function ```matmul()```, most of the time is spent by performing the innermost loop over the result array and computing its values. Therefore lines 19 and 20 would be the point where one would start optimizing the code for speed.\n",
    "\n",
    "Next we investigate the memory characteristics of our code using the ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Profile printout saved to text file matmult_functionalized.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    42     50.4 MiB     50.4 MiB   def main(print_result=True):\n",
      "    43                                 \"\"\"Main function binding together the other functions.\n",
      "    44                                 \"\"\"\n",
      "    45                             #    random.seed(314156345)\n",
      "    46     50.4 MiB      0.0 MiB       N = 250\n",
      "    47     50.6 MiB      0.2 MiB       X = get_X(N)\n",
      "    48     51.2 MiB      0.5 MiB       Y = get_Y(N)\n",
      "    49     53.4 MiB      2.2 MiB       result = matmult(X,Y)\n",
      "    50     53.4 MiB      0.0 MiB       if print_result:\n",
      "    51                                     for r in result:\n",
      "    52                                         print(r)\n",
      "    53                                 \n",
      "    54     53.4 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -T matmult_functionalized.py.mprof -f mf.main mf.main(print_result=False)\n",
    "print(open('matmult_functionalized.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above's output is somewhat confusing. We can see that most memory is created when the main function is entered, i.e., when the program starts. The overall memory consumption is, howerver, low and the increment in the program is just a few MB where arrays are populated. Optimizing for memory use seems thus not very necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ```phi()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "          151506 function calls in 11.782 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 24 to 8 due to restriction <8>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   11.782   11.782 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   11.782   11.782 <string>:1(<module>)\n",
      "        1    0.006    0.006   11.782   11.782 euler72.py:62(main)\n",
      "     9999   11.720    0.001   11.774    0.001 euler72.py:36(phi)\n",
      "     9999    0.042    0.000    0.054    0.000 euler72.py:22(factorize)\n",
      "    99314    0.009    0.000    0.009    0.000 {built-in method math.sqrt}\n",
      "    32153    0.004    0.000    0.004    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.001    0.001    0.001    0.001 euler72.py:5(gen_primes)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff0e80d7a50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = %prun -r -q euler72.main(fast=False)\n",
    "ps.sort_stats('cumulative').print_stats(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the time is spent inside the function ```phi()```. Thus speed optimization is most effective there. The program comes with an alternative function ```fast_phi()```, which is profiled further below. In order to see, which line takes longest to execute, we look at the output of ```line_profiler```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.221107 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: factorize at line 22\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    22                                           def factorize(n, primes):\n",
      "    23      9999       6576.0      0.7      3.0      factors = []\n",
      "    24      9999       4404.0      0.4      2.0      init_n = n\n",
      "    25     96347      36324.0      0.4     16.4      for p in primes:\n",
      "    26    118736      63692.0      0.5     28.8          while(n%p == 0):\n",
      "    27     22389      12969.0      0.6      5.9              n = n/p\n",
      "    28     22389      21440.0      1.0      9.7              factors.append(p)\n",
      "    29     96347      56567.0      0.6     25.6          if(p > sqrt(n)):\n",
      "    30      9999       4036.0      0.4      1.8              break\n",
      "    31      9999       5047.0      0.5      2.3      if(n > 1):\n",
      "    32      9596       6471.0      0.7      2.9          factors.append(n)\n",
      "    33      9999       3581.0      0.4      1.6      return factors\n",
      "\n",
      "Total time: 190.32 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: phi at line 36\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    36                                           def phi(n, primes):\n",
      "    37      9999     371527.0     37.2      0.2      factors = factorize(n,primes)\n",
      "    38      9999       4618.0      0.5      0.0      p = 1\n",
      "    39                                           \n",
      "    40  49995000   20049477.0      0.4     10.5      for i in range(2,n):\n",
      "    41  49985001   18452884.0      0.4      9.7          flag = True\n",
      "    42 140823164   55992201.0      0.4     29.4          for f in factors:\n",
      "    43 110435678   48944283.0      0.4     25.7              if i%f == 0:\n",
      "    44  19597515    7388800.0      0.4      3.9                  flag = False\n",
      "    45  19597515    7631411.0      0.4      4.0                  break\n",
      "    46  49985001   19030782.0      0.4     10.0          if flag:\n",
      "    47  30387486   12449282.0      0.4      6.5              p+=1\n",
      "    48      9999       5099.0      0.5      0.0      return p\n",
      "\n",
      "Total time: 354.719 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: main at line 62\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    62                                           def main(fast=True):\n",
      "    63         1       5255.0   5255.0      0.0      primes = gen_primes(1000)\n",
      "    64         1          3.0      3.0      0.0      m = 10000\n",
      "    65                                               #m = 8\n",
      "    66         1          1.0      1.0      0.0      fraq = 0\n",
      "    67         1          1.0      1.0      0.0      if fast:\n",
      "    68                                                   for i in range(2,m+1):\n",
      "    69                                                       fraq += fast_phi(i,primes)\n",
      "    70                                               else:\n",
      "    71     10000       5937.0      0.6      0.0          for i in range(2,m+1):\n",
      "    72      9999  354707297.0  35474.3    100.0              fraq += phi(i,primes)\n",
      "    73                                           \n",
      "    74         1        128.0    128.0      0.0      print(fraq)\n",
      "    75         1          1.0      1.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f euler72.main -f euler72.phi -f euler72.factorize euler72.main(fast=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that most of the time is spent executing lines 41-48 in function ```phi()```. These lines include two loops and logic operations, which should be the point to look out for speed optimizations. Finally we look at the memory consumption of the program using ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485\n",
      "\n",
      "\n",
      "*** Profile printout saved to text file euler72_slow.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    62     52.3 MiB     52.3 MiB   def main(fast=True):\n",
      "    63     52.3 MiB      0.0 MiB       primes = gen_primes(1000)\n",
      "    64     52.3 MiB      0.0 MiB       m = 10000\n",
      "    65                                 #m = 8\n",
      "    66     52.3 MiB      0.0 MiB       fraq = 0\n",
      "    67     52.3 MiB      0.0 MiB       if fast:\n",
      "    68                                     for i in range(2,m+1):\n",
      "    69                                         fraq += fast_phi(i,primes)\n",
      "    70                                 else:\n",
      "    71     52.3 MiB      0.0 MiB           for i in range(2,m+1):\n",
      "    72     52.3 MiB      0.0 MiB               fraq += phi(i,primes)\n",
      "    73                             \n",
      "    74     52.3 MiB      0.0 MiB       print(fraq)\n",
      "    75     52.3 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "#%reload_ext memory_profiler\n",
    "%mprun -T euler72_slow.py.mprof -f euler72.main euler72.main(fast=False)\n",
    "print(open('euler72_slow.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ```fast_phi()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "          161505 function calls in 0.058 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.058    0.058 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.058    0.058 <string>:1(<module>)\n",
      "        1    0.003    0.003    0.058    0.058 euler72.py:62(main)\n",
      "     9999    0.011    0.000    0.054    0.000 euler72.py:51(fast_phi)\n",
      "     9999    0.033    0.000    0.042    0.000 euler72.py:22(factorize)\n",
      "    99314    0.007    0.000    0.007    0.000 {built-in method math.sqrt}\n",
      "    32153    0.002    0.000    0.002    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.001    0.001    0.001    0.001 euler72.py:5(gen_primes)\n",
      "    10000    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff0e80ef150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r -q euler72.main()\n",
    "pff.sort_stats('cumulative').print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of the time is spent in function ```factorize()``` starting in line 23, which is called by the function ```fast_pi()```, which in turn is called by ```main()```. Thus speed optimization seems to be most fruitful inside the factorize function. In comparison with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.201643 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: factorize at line 22\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    22                                           def factorize(n, primes):\n",
      "    23      9999       3953.0      0.4      2.0      factors = []\n",
      "    24      9999       3920.0      0.4      1.9      init_n = n\n",
      "    25     96347      38845.0      0.4     19.3      for p in primes:\n",
      "    26    118736      65316.0      0.6     32.4          while(n%p == 0):\n",
      "    27     22389      10041.0      0.4      5.0              n = n/p\n",
      "    28     22389      11156.0      0.5      5.5              factors.append(p)\n",
      "    29     96347      50990.0      0.5     25.3          if(p > sqrt(n)):\n",
      "    30      9999       4249.0      0.4      2.1              break\n",
      "    31      9999       4448.0      0.4      2.2      if(n > 1):\n",
      "    32      9596       5059.0      0.5      2.5          factors.append(n)\n",
      "    33      9999       3666.0      0.4      1.8      return factors\n",
      "\n",
      "Total time: 0.411533 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: fast_phi at line 51\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    51                                           def fast_phi(n, primes):\n",
      "    52      9999     358595.0     35.9     87.1      factors = factorize(n,primes)\n",
      "    53      9999       5171.0      0.5      1.3      phi = factors[0]-1\n",
      "    54     31985      18229.0      0.6      4.4      for i in range(1,len(factors)):\n",
      "    55     21986      12307.0      0.6      3.0          if(factors[i] == factors[i-1]):\n",
      "    56      7685       5627.0      0.7      1.4              phi *= (factors[i]-1)*(factors[i])/(factors[i]-1)\n",
      "    57                                                   else:\n",
      "    58     14301       7791.0      0.5      1.9              phi *= (factors[i]-1)\n",
      "    59      9999       3813.0      0.4      0.9      return phi\n",
      "\n",
      "Total time: 0.469934 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "Function: main at line 62\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    62                                           def main(fast=True):\n",
      "    63         1       2637.0   2637.0      0.6      primes = gen_primes(1000)\n",
      "    64         1          1.0      1.0      0.0      m = 10000\n",
      "    65                                               #m = 8\n",
      "    66         1          1.0      1.0      0.0      fraq = 0\n",
      "    67         1          0.0      0.0      0.0      if fast:\n",
      "    68     10000       5067.0      0.5      1.1          for i in range(2,m+1):\n",
      "    69      9999     462113.0     46.2     98.3              fraq += fast_phi(i,primes)\n",
      "    70                                               else:\n",
      "    71                                                   for i in range(2,m+1):\n",
      "    72                                                       fraq += phi(i,primes)\n",
      "    73                                           \n",
      "    74         1        114.0    114.0      0.0      print(fraq)\n",
      "    75         1          1.0      1.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f euler72.main -f euler72.fast_phi -f euler72.factorize euler72.main()\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the line-by-line results, we observe that the line calling function ```fast_phi()``` requires most execution time inside ```main()```. However, in comparison with the implementation of ```phi()```, most time inside ```fast_phi()``` is now spent on factorizing the prime number inside ```factorize()```. We therefore see that the optimizations have had a significant impact. The new version avoids a double loop and significantly simplifies the logic.\n",
    "\n",
    "Finally, we have a look at the memory consumption using ```memory_profiler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30397485.0\n",
      "\n",
      "\n",
      "*** Profile printout saved to text file euler72.py.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/euler72.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    62     52.4 MiB     52.4 MiB   def main(fast=True):\n",
      "    63     52.4 MiB      0.0 MiB       primes = gen_primes(1000)\n",
      "    64     52.4 MiB      0.0 MiB       m = 10000\n",
      "    65                                 #m = 8\n",
      "    66     52.4 MiB      0.0 MiB       fraq = 0\n",
      "    67     52.4 MiB      0.0 MiB       if fast:\n",
      "    68     52.4 MiB      0.0 MiB           for i in range(2,m+1):\n",
      "    69     52.4 MiB      0.0 MiB               fraq += fast_phi(i,primes)\n",
      "    70                                 else:\n",
      "    71                                     for i in range(2,m+1):\n",
      "    72                                         fraq += phi(i,primes)\n",
      "    73                             \n",
      "    74     52.4 MiB      0.0 MiB       print(fraq)\n",
      "    75     52.4 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -T euler72.py.mprof -f euler72.main euler72.main()\n",
    "print(open('euler72.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the code for speed, we replace many of the loops with generator expressions and make use of Python's built-in function ```sum()``` for Python arrays, which is expected to speed up the evaluation of the matrix multiplication, which was identified to be the bottleneck of this code in step 3a). This optimization is taken from:\n",
    "\n",
    "https://www.programiz.com/python-programming/examples/multiply-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture time_mfo_main\n",
    "%timeit mfo.main(print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture time_mf_main\n",
    "%timeit mf.main(print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 s +- 12.3 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "1.59 s ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(str(time_mfo_main).split('\\n')[-2])\n",
    "%timeit mfo.main(print_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 s +- 139 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "3.21 s ± 15.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(str(time_mf_main).split('\\n')[-2])\n",
    "%timeit mf.main(print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above's output we see that the execution time of our program has measurably improved due to the optimizations we have performed (it nearly halved). Using profilers, we investigate where the performance has been improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          16472817 function calls in 2.944 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.126    3.126 {built-in method builtins.exec}\n",
      "        1    0.001    0.001    3.126    3.126 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.125    3.125 matmult_functionalized_opt.py:27(main)\n",
      "        1    0.000    0.000    2.899    2.899 matmult_functionalized_opt.py:7(matmult)\n",
      "        1    0.003    0.003    2.899    2.899 matmult_functionalized_opt.py:12(<listcomp>)\n",
      "    62750    1.182    0.000    2.743    0.000 {built-in method builtins.sum}\n",
      " 15750250    1.561    0.000    1.561    0.000 matmult_functionalized_opt.py:12(<genexpr>)\n",
      "   125250    0.033    0.000    0.197    0.000 random.py:218(randint)\n",
      "   125250    0.071    0.000    0.164    0.000 random.py:174(randrange)\n",
      "        1    0.000    0.000    0.120    0.120 matmult_functionalized_opt.py:21(get_Y)\n",
      "        1    0.000    0.000    0.120    0.120 matmult_functionalized_opt.py:24(<listcomp>)\n",
      "        1    0.000    0.000    0.106    0.106 matmult_functionalized_opt.py:15(get_X)\n",
      "        1    0.000    0.000    0.106    0.106 matmult_functionalized_opt.py:18(<listcomp>)\n",
      "   125250    0.066    0.000    0.093    0.000 random.py:224(_randbelow)\n",
      "   158807    0.020    0.000    0.020    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "   125250    0.008    0.000    0.008    0.000 {method 'bit_length' of 'int' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff0d9ef7690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pff = %prun -r mfo.main(print_result=False)\n",
    "pff.sort_stats('cumulative').print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the profiling results it seems that our improvements have decreased the time spent in functions ```matmult()```, ```get_X()```, and ```get_Y()``` by a little bit, but not by an amount that explains the difference in execution time observed earlier. Since profiling influences the execution speed and it might influence execution speeds of different implementations differntly, we cannot draw meaningful conclusions from here. Thus we move on to the ```line_profiler```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 4.30291 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: matmult at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def matmult(X,Y):\n",
      "     8                                               return [[sum(a*b for a,b in zip(X_row,Y_col)) for Y_col in zip(*Y)] for X_row in X]\n",
      "\n",
      "Total time: 0.291762 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: get_X at line 15\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    15                                           \n",
      "    16                                           \n",
      "    17                                           def get_Y(N):\n",
      "    18         1     291762.0 291762.0    100.0      \"\"\"Return random Nx(N+1) numpy matrix\n",
      "    19                                               \"\"\"\n",
      "    20                                               return [[random.randinit(0,100) for j in range(N+1)] for i in range(N)]\n",
      "\n",
      "Total time: 0.269441 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: get_Y at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                           \n",
      "    22                                           \n",
      "    23                                           def main(print_result=True):\n",
      "    24         1     269441.0 269441.0    100.0      \"\"\"Main function binding together the other functions.\n",
      "    25                                               \"\"\"\n",
      "    26                                           #    random.seed(314156345)\n",
      "    27                                               N = 250\n",
      "    28                                               X = get_X(N)\n",
      "    29                                               Y = get_Y(N)\n",
      "    30                                               result = matmult(X,Y)\n",
      "    31                                               if print_result:\n",
      "    32                                                   for r in result:\n",
      "    33                                                       print(r)\n",
      "    34                                               \n",
      "    35                                               return 0\n",
      "\n",
      "Total time: 4.86415 s\n",
      "File: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "Function: main at line 27\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    27                                               N = 250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprof_obj = %lprun -r -f mfo.matmult -f mfo.get_X -f mfo.get_Y -f mfo.main mfo.main(print_result=False)\n",
    "lprof_obj.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the relative time spent in the functions has changed significantly in comparison with the results from 3a). Now the matrix multiplication takes around 89% of the time, whereas it took around 98% of the time before. This means that we have managed to improve the matrix multiplication execution speed by more than we managed to decrease the array creation speed in ```get_X()``` and ```get_Y()```. Lastly we have a look at the memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Profile printout saved to text file matmult_functionalized_opt.py.main.mprof. \n",
      "Filename: /home/paul/git/ASPP_course/day2_exercises/exc3_profiling/matmult_functionalized_opt.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "    27     51.6 MiB     51.6 MiB   def main(print_result=True):\n",
      "    28                                 \"\"\"Optimized main function binding together the other functions.\n",
      "    29                                 \"\"\"\n",
      "    30                             #    random.seed(314156345)\n",
      "    31     51.6 MiB      0.0 MiB       N = 250\n",
      "    32     51.6 MiB      0.0 MiB       X = get_X(N)\n",
      "    33     52.1 MiB      0.5 MiB       Y = get_Y(N)\n",
      "    34     54.2 MiB      2.0 MiB       result = matmult(X,Y)\n",
      "    35     54.2 MiB      0.0 MiB       if print_result:\n",
      "    36                                     for r in result:\n",
      "    37                                         print(r)\n",
      "    38                                 \n",
      "    39     54.2 MiB      0.0 MiB       return 0\n"
     ]
    }
   ],
   "source": [
    "#%reload_ext memory_profiler\n",
    "%mprun -T matmult_functionalized_opt.py.main.mprof -f mfo.main mfo.main(print_result=False)\n",
    "print(open('matmult_functionalized_opt.py.mprof', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we generate still the same arrays, the memory requirements of the code have not changed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
